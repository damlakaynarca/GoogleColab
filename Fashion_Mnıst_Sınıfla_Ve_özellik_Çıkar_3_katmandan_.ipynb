{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrEzUFJ5lIIumXShFphX5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damlakaynarca/GoogleColab/blob/main/Fashion_Mn%C4%B1st_S%C4%B1n%C4%B1fla_Ve_%C3%B6zellik_%C3%87%C4%B1kar_3_katmandan_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SP7QSgdEMIH",
        "outputId": "5e041a2f-6b4a-4743-b2c4-cf2a8bb547ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 55s 128ms/step - loss: 0.7109 - accuracy: 0.7444 - val_loss: 0.5332 - val_accuracy: 0.8003\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 51s 121ms/step - loss: 0.4643 - accuracy: 0.8305 - val_loss: 0.4243 - val_accuracy: 0.8440\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 49s 116ms/step - loss: 0.4045 - accuracy: 0.8522 - val_loss: 0.3921 - val_accuracy: 0.8523\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 52s 123ms/step - loss: 0.3653 - accuracy: 0.8651 - val_loss: 0.3660 - val_accuracy: 0.8665\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.3374 - accuracy: 0.8758 - val_loss: 0.3417 - val_accuracy: 0.8747\n",
            "1875/1875 [==============================] - 19s 10ms/step\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "SVM Doğruluk: 0.8985\n",
            "SVM Tahminler: [8 8 7 ... 9 6 8]\n",
            "KNN Doğruluk: 0.8785\n",
            "KNN Tahminler: [8 8 7 ... 9 6 8]\n",
            "Naive Bayes Doğruluk: 0.8351666666666666\n",
            "Naive Bayes Tahminler: [8 8 7 ... 9 6 8]\n",
            "Decision Tree Doğruluk: 0.8193333333333334\n",
            "Decision Tree Tahminler: [8 8 7 ... 9 6 8]\n",
            "Lojistik Regresyon Doğruluk: 0.8935\n",
            "Lojistik Regresyon Tahminler: [8 8 7 ... 9 6 8]\n",
            "LDA Doğruluk: 0.8643333333333333\n",
            "LDA Tahminler: [8 8 7 ... 9 6 8]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Fashion MNIST veri setini yükle\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Verileri 0-1 aralığında normalize et\n",
        "\n",
        "# Verileri 4D tensöre çevir (CNN için)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Etiketleri one-hot encoding yap\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# CNN modelini oluştur\n",
        "input_layer = Input(shape=(28, 28, 1))\n",
        "conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(input_layer)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(128, kernel_size=(3, 3), activation='relu')(pool2)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "flatten = Flatten()(pool3)\n",
        "dense = Dense(128, activation='relu')(flatten)\n",
        "output_layer = Dense(10, activation='softmax')(dense)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Modeli eğit\n",
        "model.fit(x_train, y_train_cat, epochs=5, batch_size=128, validation_split=0.1)\n",
        "\n",
        "# Özellik çıkarımı (3. katmandan)\n",
        "# Özellik çıkarımı (3. katmandan)\n",
        "feature_extractor = Model(inputs=model.inputs, outputs=pool3)\n",
        "train_features = feature_extractor.predict(x_train)\n",
        "test_features = feature_extractor.predict(x_test)\n",
        "\n",
        "\n",
        "# Özellikleri düzleştir\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "test_features_flat = test_features.reshape(test_features.shape[0], -1)\n",
        "\n",
        "# Verileri ölçeklendir\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(train_features_flat)\n",
        "x_test_scaled = scaler.transform(test_features_flat)\n",
        "\n",
        "# Eğitim ve test verilerini ayır\n",
        "x_train_scaled, x_val_scaled, y_train, y_val = train_test_split(x_train_scaled, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Sınıflandırıcıları oluştur ve eğit\n",
        "svm_model = SVC()\n",
        "svm_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "lda_model = LinearDiscriminantAnalysis()\n",
        "lda_model.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Doğruluk hesapla\n",
        "svm_accuracy = svm_model.score(x_val_scaled, y_val)\n",
        "knn_accuracy = knn_model.score(x_val_scaled, y_val)\n",
        "nb_accuracy = nb_model.score(x_val_scaled, y_val)\n",
        "dt_accuracy = dt_model.score(x_val_scaled, y_val)\n",
        "lr_accuracy = lr_model.score(x_val_scaled, y_val)\n",
        "lda_accuracy = lda_model.score(x_val_scaled, y_val)\n",
        "\n",
        "# Tahminleri al ve gerçek etiketlerle karşılaştırarak hangi sınıfa ait olduğunu göster\n",
        "svm_predictions = svm_model.predict(x_val_scaled)\n",
        "knn_predictions = knn_model.predict(x_val_scaled)\n",
        "nb_predictions = nb_model.predict(x_val_scaled)\n",
        "dt_predictions = dt_model.predict(x_val_scaled)\n",
        "lr_predictions = lr_model.predict(x_val_scaled)\n",
        "lda_predictions = lda_model.predict(x_val_scaled)\n",
        "\n",
        "print(\"SVM Doğruluk:\", svm_accuracy)\n",
        "print(\"SVM Tahminler:\", svm_predictions)\n",
        "print(\"KNN Doğruluk:\", knn_accuracy)\n",
        "print(\"KNN Tahminler:\", knn_predictions)\n",
        "print(\"Naive Bayes Doğruluk:\", nb_accuracy)\n",
        "print(\"Naive Bayes Tahminler:\", nb_predictions)\n",
        "print(\"Decision Tree Doğruluk:\", dt_accuracy)\n",
        "print(\"Decision Tree Tahminler:\", dt_predictions)\n",
        "print(\"Lojistik Regresyon Doğruluk:\", lr_accuracy)\n",
        "print(\"Lojistik Regresyon Tahminler:\", lr_predictions)\n",
        "print(\"LDA Doğruluk:\", lda_accuracy)\n",
        "print(\"LDA Tahminler:\", lda_predictions)\n"
      ]
    }
  ]
}